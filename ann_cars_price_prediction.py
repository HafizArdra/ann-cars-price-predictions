# -*- coding: utf-8 -*-
"""ann-cars-price-prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OXeCBuDo4YAnU6TRPOzI2379j78lduiD

# Importing necessary libraries
"""

# Link Dataset : https://www.kaggle.com/datasets/yashpaloswal/ann-car-sales-price-prediction

# Mengunggah Dataset:
# Baris kode ini bertanggung jawab untuk mengunggah dataset dari komputer lokal ke lingkungan Google Colab menggunakan modul files dari google.colab.

from google.colab import files

# Mengunggah file
uploaded = files.upload()

# Menampilkan nama file yang diunggah
for filename in uploaded.keys():
    print('File yang diunggah:', filename)

# Import Library:
# Baris kode ini mengimpor library yang diperlukan seperti NumPy, pandas, matplotlib, seaborn, scikit-learn, dan TensorFlow.

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

# Membaca Dataset:
# Dataset dibaca ke dalam sebuah DataFrame menggunakan pd.read_csv() untuk kemudian disimpan dalam variabel df. Fungsi head() digunakan untuk menampilkan lima baris pertama dari DataFrame.

df = pd.read_csv('car_purchasing.csv', encoding='ISO-8859-1')
df.head()

# Menghapus Kolom Tidak Penting:
# Kolom-kolom yang tidak diperlukan untuk prediksi harga mobil seperti 'customer name', 'customer e-mail', 'country', dan 'gender' dihapus dari DataFrame.

df.drop(columns=['customer name', 'customer e-mail', 'country', 'gender'], inplace=True)

df.head()

df.info()
df.isna().sum()

# Menggunakan Visualisasi:
# Visualisasi dilakukan menggunakan scatter plot dan pair plot untuk memahami korelasi antara fitur-fitur yang ada dalam dataset.

plt.scatter(df['annual Salary'] , df['credit card debt'])
plt.xlabel('annual Salary')
plt.ylabel('credit card debt')
plt.title('the corr between credit card debt and annual Salary')

sns.pairplot(df)

X = df.iloc[:, :-1]
y = df.iloc[:, -1]

"""# Preprocessing"""

# Preprocessing:
# Fitur dan target variable dipisahkan menjadi X dan y. Fitur-fitur dinormalisasi menggunakan MinMaxScaler.

scale = MinMaxScaler()
X = scale.fit_transform(X)
y = scale.fit_transform(y.values.reshape(-1, 1))


# Pembagian Data:
# Dataset dibagi menjadi data pelatihan dan pengujian menggunakan train_test_split() dari scikit-learn.

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)

"""<!-- # Linear regrssion -->"""

# Regresi Linier:
# Model regresi linier dilatih pada data pelatihan dan dievaluasi pada data pengujian. Skor R-squared dihitung untuk mengevaluasi kinerja model.

#Trying linear regression
lreg = LinearRegression()
lreg.fit(X_train, y_train)
print('Train score', lreg.score(X_train, y_train))
print('Test score', lreg.score(X_test, y_test))

y_pred = lreg.predict(X_test)

"""# ANN Model"""

# Model ANN:
# Model Jaringan Saraf Tiruan (ANN) dibangun menggunakan Keras Sequential API.
# Model terdiri dari dua lapisan Dense dengan aktivasi ReLU di lapisan tersembunyi dan aktivasi linear di lapisan output.
# Model dikompilasi dengan optimizer Adam dan fungsi kerugian mean squared error.


ann = Sequential([Dense(32, activation="relu"),
                 Dense(1, activation='linear')])

ann.compile(optimizer='adam',
            loss='mean_squared_error',
            metrics=['mean_absolute_error'])


# Pelatihan dan Validasi:
# Model ANN dilatih pada data pelatihan dengan validasi split 20% selama 50 epoch.
# Kerugian dan akurasi pelatihan dan validasi dipetakan selama epoch untuk memvisualisasikan kinerja model.


history = ann.fit(X_train, y_train, epochs=50, validation_split=0.2)

# Evaluasi Model:
# Skor R-squared dihitung untuk mengevaluasi kinerja model ANN pada data pengujian.
# Selain itu, model dievaluasi pada data pengujian menggunakan metode evaluate().


tr_acc = history.history['mean_absolute_error']
tr_loss = history.history['loss']
val_acc = history.history['val_mean_absolute_error']
val_loss = history.history['val_loss']
index_loss = np.argmin(val_loss)
val_lowest = val_loss[index_loss]
index_acc = np.argmin(val_acc)
acc_highest = val_acc[index_acc]
Epochs = [i+1 for i in range(len(tr_acc))]
loss_label = f'best epoch= {str(index_loss + 1)}'
acc_label = f'best epoch= {str(index_acc + 1)}'

plt.figure(figsize= (20, 8))
plt.style.use('fivethirtyeight')

plt.subplot(1, 2, 1)
plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')
plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')
plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')
plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')
plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout
plt.show()

ann_y_pred = ann.predict(X_test)

r2 = r2_score(y_test, y_pred)
print('R2 score:', r2)

ann.evaluate(X_test, y_test)

# Membuat Prediksi:
# Model ANN digunakan untuk membuat prediksi pada titik data masukan sampel.

ann.predict([[40, 70000.500, 9550,534000]])

# Visualisasi Prediksi:
# Prediksi yang dibuat oleh model regresi linier dan ANN divisualisasikan menggunakan scatter plot untuk membandingkannya dengan nilai aktual.

plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, label='Linear Regression')
plt.scatter(y_test, ann_y_pred, label='ANN')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='gray')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Predicted vs. Actual Values')
plt.legend()
plt.show()

"""**Tidak menggunakan Confusion matrix dan Classification Report karena itu digunakan untuk masalah klasifikasi, bukan untuk masalah regresi seperti pada projek ini.**

 **Confusion matrix dan Classification Report mengevaluasi kinerja model klasifikasi dengan membandingkan label kelas aktual dengan label kelas yang diprediksi.**

**Karena Anda bekerja pada masalah regresi (memprediksi harga mobil), Anda seharusnya fokus pada metrik evaluasi regresi seperti Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), dan skor R-squared (R2).**

**Jadi, alih-alih menggunakan confusion matrix dan classification report, Anda perlu memperhatikan metrik-metrik evaluasi regresi untuk mengevaluasi kinerja model Anda dalam memprediksi harga mobil. Metrik-metrik ini memberikan pemahaman tentang seberapa dekat prediksi Anda dengan nilai sebenarnya dan seberapa baik model Anda memodelkan pola dalam data.**
"""